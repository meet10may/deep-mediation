{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras==2.2.4\n",
    "# !pip install tensorflow-gpu==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/myclone/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/myclone/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/myclone/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/myclone/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/myclone/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/myclone/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0 2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.5 support is deprecated and will be removed in a future release. Consider switching to Python 3.6 or 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.__version__,keras.__version__)\n",
    "import os,sys,shap\n",
    "sys.path.append('/home/ubuntu/hacking/projects/deep-mediation/deep-mediation/src')\n",
    "import utils,build_model\n",
    "import innvestigate,shap\n",
    "import numpy as np\n",
    "from nilearn.image import load_img,mean_img\n",
    "from keras.models import load_model\n",
    "import nibabel as nib\n",
    "import create_dataset,utils\n",
    "import pandas as pd\n",
    "from nilearn.image import resample_img,concat_imgs,load_img,resample_to_img,threshold_img,smooth_img\n",
    "print(shap.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the data path and the model to use for visualization purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/ubuntu/hacking/data/stephan-data-ni-files'\n",
    "model_to_use = '/home/ubuntu/hacking/projects/deep-mediation/deep-mediation/results/deep/deep-iter-4-run-0.h5'\n",
    "img_to_use = '/home/ubuntu/hacking/data/stephan-data-ni-files/BMRK5_data/stim_bmrk5_S860_OC1339_zs.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the studies to use ['NSF', 'BMRK3', 'BMRK4', 'IE', 'ILCP', 'EXP', 'SCEBL']\n",
      "This is the test study BMRK5 \n",
      "Using 2 random images from training dataset as a background signal for Deep Shap...\n",
      "(91, 109, 91, 82)\n"
     ]
    }
   ],
   "source": [
    "num_imgs = 2\n",
    "dataset = create_dataset.generate_dataset(data_path,test_data_size=0.30)\n",
    "test_rate,test_temp,test_imgs_list,flat_test_rate,flat_test_rate_zs = utils.get_rate_temp_img(dataset,subjs='test_subjs')\n",
    "train_rate,train_temp,train_imgs_list,flat_train_rate,flat_train_rate_zs = utils.get_rate_temp_img(dataset,subjs='train_subjs')\n",
    "\n",
    "print(\"Using %s random images from training dataset as a background signal for Deep Shap...\"%num_imgs)\n",
    "random_train_imgs_list = np.array(train_imgs_list)[np.random.randint(0,146,num_imgs)]\n",
    "random_train_imgs = utils.concat_images(list(random_train_imgs_list),None)\n",
    "print(random_train_imgs.shape)\n",
    "\n",
    "\n",
    "# background = utils.concat_images(list(train_imgs_list),None)\n",
    "# background = np.rollaxis(background.get_fdata(), 3, 0)[...,None]\n",
    "\n",
    "background = np.rollaxis(random_train_imgs.get_fdata(), 3, 0)[...,None]\n",
    "test_data = utils.concat_images(list(test_imgs_list),None)\n",
    "test_data = np.rollaxis(test_data.get_fdata(), 3, 0)[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 91, 109, 91, 1) (2596, 91, 109, 91, 1)\n"
     ]
    }
   ],
   "source": [
    "print(background.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(model, background,test_data):\n",
    "    explainer = shap.DeepExplainer(model, background,keras.backend.get_session())\n",
    "#     explainer = shap.GradientExplainer(model, background,keras.backend.get_session())\n",
    "    values = []\n",
    "    for i in range(0,1000):\n",
    "        print(i)\n",
    "#         shap_values = explainer.shap_values(test_data[i:i+1,:],check_additivity=False)\n",
    "        shap_values = explainer.shap_values(test_data[i:i+1,:],check_additivity=False)\n",
    "        values.append(shap_values[0])\n",
    "    values_ = np.concatenate(values)\n",
    "    return values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "values_ = get_shap_values(model, background,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/home/ubuntu/hacking/projects/deep-mediation/deep-mediation/results/deep/deep-iter-4-run-0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset.generate_dataset(data_path,test_data_size=0.30)\n",
    "train_rate,train_temp,train_imgs_list,flat_train_rate,flat_train_rate_zs = utils.get_rate_temp_img(dataset,subjs='train_subjs')\n",
    "# val_rate,val_temp,val_imgs_list,flat_val_rate,flat_val_rate_zs = utils.get_rate_temp_img(dataset,subjs='val_subjs')\n",
    "test_rate,test_temp,test_imgs_list,flat_test_rate,flat_test_rate_zs = utils.get_rate_temp_img(dataset,subjs='test_subjs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = create_dataset.generate_dataset(data_path,test_data_size=0.30)\n",
    "# test_rate,test_temp,test_imgs_list,flat_test_rate,flat_test_rate_zs = utils.get_rate_temp_img(dataset,subjs='test_subjs')\n",
    "# df_test = pd.DataFrame()\n",
    "# df_test['X'] = test_temp\n",
    "# df_test['Y'] = flat_test_rate_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_list[0:5],test_imgs_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading training images...\")\n",
    "train_imgs = utils.concat_imgs(train_imgs_list)\n",
    "print(\"Smoothing training images...\")\n",
    "train_imgs = smooth_img(train_imgs, fwhm=[4,4,4]) #in mm \n",
    "train_imgs = np.rollaxis(train_imgs.get_fdata(), 3, 0)[...,None]\n",
    "\n",
    "print(\"Reading testing images...\")\n",
    "test_imgs = utils.concat_imgs(test_imgs_list)\n",
    "print(\"Smoothing testing images...\")\n",
    "test_imgs = smooth_img(test_imgs, fwhm=[4,4,4]) #in mm \n",
    "test_imgs = np.rollaxis(test_imgs.get_fdata(), 3, 0)[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_to_use):\n",
    "    model_with_gpu = load_model(model_to_use)\n",
    "    model = model_with_gpu.layers[-2]\n",
    "    return model\n",
    "def get_nifti_params(input_img):\n",
    "    affine = input_img.affine\n",
    "    hdr = input_img.header\n",
    "    return affine,hdr\n",
    "def get_nifti_image(array,affine,header):\n",
    "    nii_image = nib.Nifti1Image(array, affine, header)\n",
    "    return nii_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = load_img(img_to_use)\n",
    "affine,hdr = get_nifti_params(input_img)\n",
    "input_img = input_img.get_fdata()\n",
    "input_img = np.rollaxis(input_img, 3,0)[...,None]\n",
    "# print(input_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= get_model(model_to_use)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 2\n",
    "dataset = create_dataset.generate_dataset(data_path,test_data_size=0.30)\n",
    "test_rate,test_temp,test_imgs_list,flat_test_rate,flat_test_rate_zs = utils.get_rate_temp_img(dataset,subjs='test_subjs')\n",
    "train_rate,train_temp,train_imgs_list,flat_train_rate,flat_train_rate_zs = utils.get_rate_temp_img(dataset,subjs='train_subjs')\n",
    "\n",
    "print(\"Using %s random images from training dataset as a background signal for Deep Shap...\"%num_imgs)\n",
    "random_train_imgs_list = np.array(train_imgs_list)[np.random.randint(0,146,num_imgs)]\n",
    "random_train_imgs = utils.concat_images(list(random_train_imgs_list),None)\n",
    "print(random_train_imgs.shape)\n",
    "\n",
    "\n",
    "# background = utils.concat_images(list(train_imgs_list),None)\n",
    "# background = np.rollaxis(background.get_fdata(), 3, 0)[...,None]\n",
    "\n",
    "background = np.rollaxis(random_train_imgs.get_fdata(), 3, 0)[...,None]\n",
    "test_data = utils.concat_images(list(test_imgs_list[0:10]),None)\n",
    "test_data = np.rollaxis(test_data.get_fdata(), 3, 0)[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = utils.concat_images(list(test_imgs_list[0:10]),None)\n",
    "test_data = np.rollaxis(test_data.get_fdata(), 3, 0)[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = background[0:10,:]\n",
    "background.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(model, background,test_data):\n",
    "#     explainer = shap.DeepExplainer(model, background)\n",
    "    explainer = shap.GradientExplainer(model, background)\n",
    "    values = []\n",
    "    for i in range(0,test_data.shape[0]):\n",
    "        print(i)\n",
    "        shap_values = explainer.shap_values(test_data[i:i+1,:],check_additivity=False)\n",
    "        values.append(shap_values[0])\n",
    "    values_ = np.concatenate(values)\n",
    "    return values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values_ = get_shap_values(model, background,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.GradientExplainer(model.layers[-2], input_img,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for i in range(0,input_img.shape[0]):\n",
    "    print(i)\n",
    "    shap_values = explainer.shap_values(input_img[i:i+1,:])\n",
    "    values.append(shap_values[0])\n",
    "values_ = np.concatenate(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = shap.GradientExplainer(model.layers[-2], input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = e.shap_values(input_img, nsamples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
