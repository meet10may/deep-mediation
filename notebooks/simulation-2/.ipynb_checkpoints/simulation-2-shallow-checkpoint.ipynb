{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/anaconda3/envs/deep_structure/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import tensorflow as tf\n",
    "# import importlib\n",
    "sys.path.append('/home/ubuntu/hacking/projects/deep-mediation/nov2020')\n",
    "import auxiliaryfunctions\n",
    "# importlib.reload(auxiliaryfunctions)\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import zscore,norm\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,make_scorer,mean_absolute_error,r2_score\n",
    "\n",
    "# from datagenerator import dataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "early_stopping = True\n",
    "epochs = 1000\n",
    "batch_size = 4\n",
    "use_dynamic_LR=False\n",
    "# optimizer='Adam'\n",
    "algo = 'shallow' #['shallow','deep','svr'] \n",
    "patience = 50\n",
    "result_path = '/home/ubuntu/hacking/projects/deep-mediation/nov2020/results/simulation-2-results'\n",
    "num_subs = 1000\n",
    "num_iters = 20\n",
    "num_runs = 100\n",
    "new_shape = [[8,8],[32,32],[64,64]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(z,m,d,iter):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plot_distribution(z,m,labels=['z','m'])\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plot_distribution(z,d,labels=['z','d'])\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plot_scatter(z,d,labels= ['z','d'])\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plot_scatter(z,m,labels= ['z','m'])\n",
    "    # plt.savefig(os.path.join(result_path,'result'+ str(iter) +'.png'),dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_distribution(z,m,labels):\n",
    "    sns.distplot(z, hist=True, rug=True,label=labels[0]);\n",
    "    sns.distplot(m, hist=True, rug=True,label=labels[1]);\n",
    "    plt.legend()\n",
    "\n",
    "def plot_scatter(y_test,y_pred,labels):\n",
    "    r = np.corrcoef(y_pred,y_test)[0,1]\n",
    "    r = round(r,3)\n",
    "    plt.scatter(y_test,y_pred)\n",
    "    plt.xlabel(labels[0])\n",
    "    plt.ylabel(labels[1])\n",
    "    plt.title('r=%s'%r)\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def plot_error(ax,values,title,y_lab,num_iterations):\n",
    "    ax.plot(values)\n",
    "    ax.set_xlim([0,num_iterations])\n",
    "    ax.set_xlabel('#iterations')\n",
    "    ax.set_ylabel(y_lab)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def create_empty_df(num_runs,num_iters):\n",
    "    # Creates an empty dataFrame\n",
    "    a = np.empty((num_runs,num_iters))\n",
    "    a[:] = np.nan\n",
    "    dataFrame = None\n",
    "    parameters = ['alpha0', 'beta0','alpha','beta','gamma']\n",
    "    for params in parameters:\n",
    "        iter = ['iter_'+str(i) for i in range(num_iters)]\n",
    "        pdindex = pd.MultiIndex.from_product([[params], iter],\n",
    "                                             names=['parameters', 'runs']) \n",
    "        frame = pd.DataFrame(a, columns = pdindex,index = range(0,num_runs))\n",
    "        dataFrame = pd.concat([dataFrame,frame],axis=1)\n",
    "    return dataFrame\n",
    "\n",
    "def simulate_mediation(df,M,params_df,model,algo,num_subs,batch_size,epochs,tune,n,n_runs,iterations):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    early_stopping=True\n",
    "    # Initialize z with some phi\n",
    "    print(\"Using intial random model parameters\")\n",
    "#     if algo == 'svr':\n",
    "#         z = svr.predict(M.flatten())\n",
    "    z = model.predict(M) \n",
    "    try:\n",
    "        z = np.concatenate(z)\n",
    "    except:\n",
    "        pass\n",
    "    # plot_scatter(z,df.m,labels=['z','m'])\n",
    "    \n",
    "    for i in range(0,iterations):\n",
    "        print('Starting iteration... %s'%(i+1))\n",
    "        #Check for sign change\n",
    "        if np.corrcoef(z,df.Y)[0,1] < 0 :\n",
    "            z = z*(-1)\n",
    "        # Check for scaling\n",
    "        z= zscore(z)\n",
    "\n",
    "        lm = smf.ols(formula='z ~ X', data=df).fit()\n",
    "        alpha0 = lm.params.loc['Intercept']\n",
    "        alph = lm.params.loc['X'] \n",
    "\n",
    "        lm = smf.ols(formula='Y ~ z + X', data=df).fit()\n",
    "        beta0 = lm.params.Intercept \n",
    "        bet = lm.params.z\n",
    "        gam = lm.params.X \n",
    "        resid_std = np.std(lm.resid)\n",
    "        e = df.Y - beta0 - (df.X*gam)\n",
    "        h = alpha0 + df.X*alph\n",
    "        d = (((bet*e)+h)/((bet**2)+1))\n",
    "        d = zscore(d)\n",
    "        \n",
    "        if tune:\n",
    "            if algo == 'shallow':\n",
    "                if early_stopping:\n",
    "                    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,patience=50)\n",
    "                    history = model.fit(M,d,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=[es],\n",
    "                                      shuffle=True,validation_split = 0.3)\n",
    "                else:\n",
    "                    history = model.fit(M,d,batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "                                  shuffle=True,validation_split = 0.3)\n",
    "                z = model.predict(M)\n",
    "                \n",
    "            elif algo == 'svr':\n",
    "                    model = auxiliaryfunctions.create_svr_model(M,d)\n",
    "                    z = model.predict(M)\n",
    "            elif algo=='deep':\n",
    "                print(\"WIP\")\n",
    "\n",
    "        \n",
    "        params_df.loc[n_runs]['alpha0','iter_'+str(i)]=alpha0\n",
    "        params_df.loc[n_runs]['beta0','iter_'+str(i)]=beta0\n",
    "        params_df.loc[n_runs]['beta','iter_'+str(i)]=bet\n",
    "        params_df.loc[n_runs]['gamma','iter_'+str(i)]=gam\n",
    "        params_df.loc[n_runs]['alpha','iter_'+str(i)]=alph\n",
    "\n",
    "        try:\n",
    "            z = np.concatenate(z)\n",
    "        except:\n",
    "            pass\n",
    "       \n",
    "    return params_df,z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for image shape [64, 64] starting with 1 runs\n",
      "Using intial random model parameters\n",
      "Starting iteration... 1\n",
      "[-1.2310193   0.4804549  -1.292375    0.49488905  1.3081722 ]\n",
      "Epoch 1/1000\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 5175.4858 - mse: 5175.4858 - val_loss: 0.7703 - val_mse: 0.7703\n",
      "Epoch 2/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.8200 - mse: 1.8200 - val_loss: 0.2734 - val_mse: 0.2734\n",
      "Epoch 3/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.8857 - mse: 0.8857 - val_loss: 0.2010 - val_mse: 0.2010\n",
      "Epoch 4/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.5344 - mse: 0.5344 - val_loss: 0.1215 - val_mse: 0.1215\n",
      "Epoch 5/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.4361 - mse: 0.4361 - val_loss: 0.1100 - val_mse: 0.1100\n",
      "Epoch 6/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.3166 - mse: 0.3166 - val_loss: 0.1100 - val_mse: 0.1100\n",
      "Epoch 7/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.2778 - mse: 0.2778 - val_loss: 0.0927 - val_mse: 0.0927\n",
      "Epoch 8/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.2157 - mse: 0.2157 - val_loss: 0.0841 - val_mse: 0.0841\n",
      "Epoch 9/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.2132 - mse: 0.2132 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 10/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1740 - mse: 0.1740 - val_loss: 0.0734 - val_mse: 0.0734\n",
      "Epoch 11/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1533 - mse: 0.1533 - val_loss: 0.0673 - val_mse: 0.0673\n",
      "Epoch 12/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1591 - mse: 0.1591 - val_loss: 0.0693 - val_mse: 0.0693\n",
      "Epoch 13/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1388 - mse: 0.1388 - val_loss: 0.0675 - val_mse: 0.0675\n",
      "Epoch 14/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1487 - mse: 0.1487 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 15/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1218 - mse: 0.1218 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 16/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1208 - mse: 0.1208 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 17/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 18/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1227 - mse: 0.1227 - val_loss: 0.0626 - val_mse: 0.0626\n",
      "Epoch 19/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1066 - mse: 0.1066 - val_loss: 0.0570 - val_mse: 0.0570\n",
      "Epoch 20/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0579 - val_mse: 0.0579\n",
      "Epoch 21/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0982 - mse: 0.0982 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Epoch 22/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 23/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0985 - mse: 0.0985 - val_loss: 0.0579 - val_mse: 0.0579\n",
      "Epoch 24/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 25/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1035 - mse: 0.1035 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 26/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0956 - mse: 0.0956 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 27/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 28/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0979 - mse: 0.0979 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 29/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 30/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 31/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 32/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 33/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0924 - mse: 0.0924 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 34/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 35/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 36/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0862 - mse: 0.0862 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 37/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0827 - mse: 0.0827 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 38/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 39/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 40/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 41/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0954 - mse: 0.0954 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 42/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0823 - mse: 0.0823 - val_loss: 0.0606 - val_mse: 0.0606\n",
      "Epoch 43/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0550 - val_mse: 0.0550\n",
      "Epoch 44/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 45/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 46/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 47/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0811 - mse: 0.0811 - val_loss: 0.0572 - val_mse: 0.0572\n",
      "Epoch 48/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 49/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 50/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 51/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0830 - mse: 0.0830 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 52/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0822 - mse: 0.0822 - val_loss: 0.0585 - val_mse: 0.0585\n",
      "Epoch 53/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0846 - mse: 0.0846 - val_loss: 0.0572 - val_mse: 0.0572\n",
      "Epoch 54/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 55/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 56/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0910 - mse: 0.0910 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 57/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0810 - mse: 0.0810 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 58/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0776 - mse: 0.0776 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 59/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0795 - mse: 0.0795 - val_loss: 0.0533 - val_mse: 0.0533\n",
      "Epoch 60/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 61/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0783 - mse: 0.0783 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 62/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 63/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0816 - mse: 0.0816 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 64/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 0.0570 - val_mse: 0.0570\n",
      "Epoch 65/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0769 - mse: 0.0769 - val_loss: 0.0582 - val_mse: 0.0582\n",
      "Epoch 66/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 67/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0852 - mse: 0.0852 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 68/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 0.0540 - val_mse: 0.0540\n",
      "Epoch 69/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 70/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.0587 - val_mse: 0.0587\n",
      "Epoch 71/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 72/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0783 - mse: 0.0783 - val_loss: 0.0555 - val_mse: 0.0555\n",
      "Epoch 73/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 74/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 75/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0543 - val_mse: 0.0543\n",
      "Epoch 76/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0755 - mse: 0.0755 - val_loss: 0.0549 - val_mse: 0.0549\n",
      "Epoch 77/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.0608 - val_mse: 0.0608\n",
      "Epoch 78/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 79/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0565 - val_mse: 0.0565\n",
      "Epoch 80/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0776 - mse: 0.0776 - val_loss: 0.0709 - val_mse: 0.0709\n",
      "Epoch 81/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0743 - mse: 0.0743 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 82/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0734 - mse: 0.0734 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 83/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0496 - val_mse: 0.0496\n",
      "Epoch 84/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 85/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 86/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 87/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0734 - mse: 0.0734 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 88/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 89/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0731 - mse: 0.0731 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 90/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 91/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0771 - mse: 0.0771 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 92/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0828 - mse: 0.0828 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 93/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0713 - mse: 0.0713 - val_loss: 0.0538 - val_mse: 0.0538\n",
      "Epoch 94/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0532 - val_mse: 0.0532\n",
      "Epoch 95/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0804 - mse: 0.0804 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 96/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0765 - mse: 0.0765 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Starting iteration... 2\n",
      "[ 1.0040083  1.5429516 -0.5128279  0.4624164  0.816207 ]\n",
      "Epoch 1/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1813 - mse: 0.1813 - val_loss: 0.1027 - val_mse: 0.1027\n",
      "Epoch 2/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1706 - mse: 0.1706 - val_loss: 0.0952 - val_mse: 0.0952\n",
      "Epoch 3/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1640 - mse: 0.1640 - val_loss: 0.0988 - val_mse: 0.0988\n",
      "Epoch 4/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1513 - mse: 0.1513 - val_loss: 0.0828 - val_mse: 0.0828\n",
      "Epoch 5/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1526 - mse: 0.1526 - val_loss: 0.1069 - val_mse: 0.1069\n",
      "Epoch 6/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1629 - mse: 0.1629 - val_loss: 0.1157 - val_mse: 0.1157\n",
      "Epoch 7/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1345 - mse: 0.1345 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 8/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1388 - mse: 0.1388 - val_loss: 0.1232 - val_mse: 0.1232\n",
      "Epoch 9/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1434 - mse: 0.1434 - val_loss: 0.0857 - val_mse: 0.0857\n",
      "Epoch 10/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 0.0836 - val_mse: 0.0836\n",
      "Epoch 11/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1337 - mse: 0.1337 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 12/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1251 - mse: 0.1251 - val_loss: 0.0906 - val_mse: 0.0906\n",
      "Epoch 13/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1456 - mse: 0.1456 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 14/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1455 - mse: 0.1455 - val_loss: 0.1057 - val_mse: 0.1057\n",
      "Epoch 15/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1370 - mse: 0.1370 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 16/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1335 - mse: 0.1335 - val_loss: 0.1000 - val_mse: 0.1000\n",
      "Epoch 17/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1300 - mse: 0.1300 - val_loss: 0.1123 - val_mse: 0.1123\n",
      "Epoch 18/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1347 - mse: 0.1347 - val_loss: 0.0898 - val_mse: 0.0898\n",
      "Epoch 19/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1359 - mse: 0.1359 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 20/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1141 - mse: 0.1141 - val_loss: 0.0912 - val_mse: 0.0912\n",
      "Epoch 21/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 0.0890 - val_mse: 0.0890\n",
      "Epoch 22/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1166 - mse: 0.1166 - val_loss: 0.0882 - val_mse: 0.0882\n",
      "Epoch 23/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1394 - mse: 0.1394 - val_loss: 0.0889 - val_mse: 0.0889\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1230 - mse: 0.1230 - val_loss: 0.0864 - val_mse: 0.0864\n",
      "Epoch 25/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1043 - mse: 0.1043 - val_loss: 0.0969 - val_mse: 0.0969\n",
      "Epoch 26/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 0.0846 - val_mse: 0.0846\n",
      "Epoch 27/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1226 - mse: 0.1226 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 28/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1155 - mse: 0.1155 - val_loss: 0.0859 - val_mse: 0.0859\n",
      "Epoch 29/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1222 - mse: 0.1222 - val_loss: 0.0856 - val_mse: 0.0856\n",
      "Epoch 30/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1213 - mse: 0.1213 - val_loss: 0.0942 - val_mse: 0.0942\n",
      "Epoch 31/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1257 - mse: 0.1257 - val_loss: 0.0869 - val_mse: 0.0869\n",
      "Epoch 32/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1131 - mse: 0.1131 - val_loss: 0.0992 - val_mse: 0.0992\n",
      "Epoch 33/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.2008 - mse: 0.2008 - val_loss: 0.1050 - val_mse: 0.1050\n",
      "Epoch 34/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1221 - mse: 0.1221 - val_loss: 0.0857 - val_mse: 0.0857\n",
      "Epoch 35/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1388 - mse: 0.1388 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 36/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1289 - mse: 0.1289 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 37/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1282 - mse: 0.1282 - val_loss: 0.0777 - val_mse: 0.0777\n",
      "Epoch 38/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1095 - mse: 0.1095 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 39/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1239 - mse: 0.1239 - val_loss: 0.0888 - val_mse: 0.0888\n",
      "Epoch 40/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1081 - mse: 0.1081 - val_loss: 0.0907 - val_mse: 0.0907\n",
      "Epoch 41/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1313 - mse: 0.1313 - val_loss: 0.0812 - val_mse: 0.0812\n",
      "Epoch 42/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1361 - mse: 0.1361 - val_loss: 0.0853 - val_mse: 0.0853\n",
      "Epoch 43/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 44/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1328 - mse: 0.1328 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 45/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1285 - mse: 0.1285 - val_loss: 0.0910 - val_mse: 0.0910\n",
      "Epoch 46/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1210 - mse: 0.1210 - val_loss: 0.0839 - val_mse: 0.0839\n",
      "Epoch 47/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1196 - mse: 0.1196 - val_loss: 0.0872 - val_mse: 0.0872\n",
      "Epoch 48/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1096 - mse: 0.1096 - val_loss: 0.1117 - val_mse: 0.1117\n",
      "Epoch 49/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1097 - mse: 0.1097 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 50/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.0903 - val_mse: 0.0903\n",
      "Epoch 51/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1148 - mse: 0.1148 - val_loss: 0.0840 - val_mse: 0.0840\n",
      "Epoch 52/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1282 - mse: 0.1282 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 53/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1249 - mse: 0.1249 - val_loss: 0.0900 - val_mse: 0.0900\n",
      "Epoch 54/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1142 - mse: 0.1142 - val_loss: 0.0849 - val_mse: 0.0849\n",
      "Epoch 55/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1124 - mse: 0.1124 - val_loss: 0.0937 - val_mse: 0.0937\n",
      "Epoch 56/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1099 - mse: 0.1099 - val_loss: 0.1108 - val_mse: 0.1108\n",
      "Epoch 57/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1126 - mse: 0.1126 - val_loss: 0.0953 - val_mse: 0.0953\n",
      "Epoch 58/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1049 - mse: 0.1049 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 59/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1117 - mse: 0.1117 - val_loss: 0.0879 - val_mse: 0.0879\n",
      "Epoch 60/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1076 - mse: 0.1076 - val_loss: 0.0819 - val_mse: 0.0819\n",
      "Epoch 61/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 0.0975 - val_mse: 0.0975\n",
      "Epoch 62/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 0.0865 - val_mse: 0.0865\n",
      "Epoch 63/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 0.0927 - val_mse: 0.0927\n",
      "Epoch 64/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1189 - mse: 0.1189 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 65/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1237 - mse: 0.1237 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 66/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1090 - mse: 0.1090 - val_loss: 0.0864 - val_mse: 0.0864\n",
      "Epoch 67/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1129 - mse: 0.1129 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 68/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 0.0875 - val_mse: 0.0875\n",
      "Epoch 69/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1171 - mse: 0.1171 - val_loss: 0.0979 - val_mse: 0.0979\n",
      "Epoch 70/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1061 - mse: 0.1061 - val_loss: 0.0867 - val_mse: 0.0867\n",
      "Epoch 71/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1041 - mse: 0.1041 - val_loss: 0.0845 - val_mse: 0.0845\n",
      "Epoch 72/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1180 - mse: 0.1180 - val_loss: 0.0949 - val_mse: 0.0949\n",
      "Epoch 73/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0894 - val_mse: 0.0894\n",
      "Epoch 74/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1069 - mse: 0.1069 - val_loss: 0.0957 - val_mse: 0.0957\n",
      "Epoch 75/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1081 - mse: 0.1081 - val_loss: 0.0930 - val_mse: 0.0930\n",
      "Epoch 76/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.0875 - val_mse: 0.0875\n",
      "Epoch 77/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 0.0857 - val_mse: 0.0857\n",
      "Epoch 78/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1285 - mse: 0.1285 - val_loss: 0.0875 - val_mse: 0.0875\n",
      "Epoch 79/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 0.0834 - val_mse: 0.0834\n",
      "Epoch 80/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.0816 - val_mse: 0.0816\n",
      "Epoch 81/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1134 - mse: 0.1134 - val_loss: 0.0849 - val_mse: 0.0849\n",
      "Epoch 82/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1123 - mse: 0.1123 - val_loss: 0.0901 - val_mse: 0.0901\n",
      "Epoch 83/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1126 - mse: 0.1126 - val_loss: 0.0795 - val_mse: 0.0795\n",
      "Epoch 84/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1133 - mse: 0.1133 - val_loss: 0.0911 - val_mse: 0.0911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 86/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1090 - mse: 0.1090 - val_loss: 0.1095 - val_mse: 0.1095\n",
      "Epoch 87/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1215 - mse: 0.1215 - val_loss: 0.0875 - val_mse: 0.0875\n",
      "Starting iteration... 3\n",
      "[ 1.2723618   1.5947986  -0.65340734  0.39822632  0.92985535]\n",
      "Epoch 1/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1274 - mse: 0.1274 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 2/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1095 - mse: 0.1095 - val_loss: 0.1087 - val_mse: 0.1087\n",
      "Epoch 3/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1135 - mse: 0.1135 - val_loss: 0.0849 - val_mse: 0.0849\n",
      "Epoch 4/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1099 - mse: 0.1099 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 5/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 6/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 0.0831 - val_mse: 0.0831\n",
      "Epoch 7/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0934 - mse: 0.0934 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 8/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 9/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1068 - mse: 0.1068 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 10/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 11/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1072 - mse: 0.1072 - val_loss: 0.0814 - val_mse: 0.0814\n",
      "Epoch 12/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.0793 - val_mse: 0.0793\n",
      "Epoch 13/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1133 - mse: 0.1133 - val_loss: 0.0902 - val_mse: 0.0902\n",
      "Epoch 14/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1034 - mse: 0.1034 - val_loss: 0.0844 - val_mse: 0.0844\n",
      "Epoch 15/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1101 - mse: 0.1101 - val_loss: 0.0845 - val_mse: 0.0845\n",
      "Epoch 16/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 0.0830 - val_mse: 0.0830\n",
      "Epoch 17/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1062 - mse: 0.1062 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Epoch 18/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1015 - mse: 0.1015 - val_loss: 0.0902 - val_mse: 0.0902\n",
      "Epoch 19/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1004 - mse: 0.1004 - val_loss: 0.0812 - val_mse: 0.0812\n",
      "Epoch 20/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 0.0797 - val_mse: 0.0797\n",
      "Epoch 21/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1074 - mse: 0.1074 - val_loss: 0.0846 - val_mse: 0.0846\n",
      "Epoch 22/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1033 - mse: 0.1033 - val_loss: 0.0847 - val_mse: 0.0847\n",
      "Epoch 23/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.0946 - val_mse: 0.0946\n",
      "Epoch 24/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1029 - mse: 0.1029 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 25/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1000 - mse: 0.1000 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 26/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1076 - mse: 0.1076 - val_loss: 0.0846 - val_mse: 0.0846\n",
      "Epoch 27/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0978 - mse: 0.0978 - val_loss: 0.0800 - val_mse: 0.0800\n",
      "Epoch 28/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1064 - mse: 0.1064 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 29/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1211 - mse: 0.1211 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 30/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 0.0804 - val_mse: 0.0804\n",
      "Epoch 31/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0981 - mse: 0.0981 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 32/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0996 - mse: 0.0996 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 33/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 34/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 0.0812 - val_mse: 0.0812\n",
      "Epoch 35/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 0.0909 - val_mse: 0.0909\n",
      "Epoch 36/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0963 - mse: 0.0963 - val_loss: 0.0833 - val_mse: 0.0833\n",
      "Epoch 37/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 38/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 39/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 40/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0985 - mse: 0.0985 - val_loss: 0.0871 - val_mse: 0.0871\n",
      "Epoch 41/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0899 - mse: 0.0899 - val_loss: 0.0800 - val_mse: 0.0800\n",
      "Epoch 42/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1022 - mse: 0.1022 - val_loss: 0.0804 - val_mse: 0.0804\n",
      "Epoch 43/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1112 - mse: 0.1112 - val_loss: 0.0861 - val_mse: 0.0861\n",
      "Epoch 44/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 0.0928 - val_mse: 0.0928\n",
      "Epoch 45/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 0.0978 - val_mse: 0.0978\n",
      "Epoch 46/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0946 - mse: 0.0946 - val_loss: 0.0843 - val_mse: 0.0843\n",
      "Epoch 47/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0910 - mse: 0.0910 - val_loss: 0.0841 - val_mse: 0.0841\n",
      "Epoch 48/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1034 - mse: 0.1034 - val_loss: 0.0856 - val_mse: 0.0856\n",
      "Epoch 49/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1008 - mse: 0.1008 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Epoch 50/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1063 - mse: 0.1063 - val_loss: 0.1018 - val_mse: 0.1018\n",
      "Epoch 51/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1105 - mse: 0.1105 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 52/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0978 - mse: 0.0978 - val_loss: 0.0861 - val_mse: 0.0861\n",
      "Epoch 53/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0964 - mse: 0.0964 - val_loss: 0.0837 - val_mse: 0.0837\n",
      "Epoch 54/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1137 - mse: 0.1137 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 55/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1127 - mse: 0.1127 - val_loss: 0.0825 - val_mse: 0.0825\n",
      "Epoch 56/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0825 - val_mse: 0.0825\n",
      "Epoch 57/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 0.0838 - val_mse: 0.0838\n",
      "Epoch 58/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 59/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 60/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 0.0879 - val_mse: 0.0879\n",
      "Epoch 61/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0885 - val_mse: 0.0885\n",
      "Epoch 62/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 63/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 64/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 65/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0977 - mse: 0.0977 - val_loss: 0.0800 - val_mse: 0.0800\n",
      "Epoch 66/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1011 - mse: 0.1011 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 67/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 0.0789 - val_mse: 0.0789\n",
      "Epoch 68/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 69/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0952 - mse: 0.0952 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 70/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1184 - mse: 0.1184 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "Epoch 71/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 72/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1025 - mse: 0.1025 - val_loss: 0.0795 - val_mse: 0.0795\n",
      "Epoch 73/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0881 - mse: 0.0881 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 74/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1040 - mse: 0.1040 - val_loss: 0.0931 - val_mse: 0.0931\n",
      "Epoch 75/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1068 - mse: 0.1068 - val_loss: 0.0797 - val_mse: 0.0797\n",
      "Epoch 76/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0789 - mse: 0.0789 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 77/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 78/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1019 - mse: 0.1019 - val_loss: 0.0870 - val_mse: 0.0870\n",
      "Epoch 79/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0875 - mse: 0.0875 - val_loss: 0.0848 - val_mse: 0.0848\n",
      "Epoch 80/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0957 - mse: 0.0957 - val_loss: 0.0864 - val_mse: 0.0864\n",
      "Epoch 81/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 0.0944 - val_mse: 0.0944\n",
      "Epoch 82/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 83/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0969 - mse: 0.0969 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 84/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0981 - mse: 0.0981 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 85/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 86/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 87/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 0.0789 - val_mse: 0.0789\n",
      "Epoch 88/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0789 - val_mse: 0.0789\n",
      "Epoch 89/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 90/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 91/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.0781 - val_mse: 0.0781\n",
      "Epoch 92/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0985 - mse: 0.0985 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 93/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 94/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 95/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0949 - mse: 0.0949 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 96/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0957 - mse: 0.0957 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 97/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1020 - mse: 0.1020 - val_loss: 0.0886 - val_mse: 0.0886\n",
      "Epoch 98/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0874 - mse: 0.0874 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 99/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 0.0803 - val_mse: 0.0803\n",
      "Epoch 100/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0796 - val_mse: 0.0796\n",
      "Epoch 101/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1012 - mse: 0.1012 - val_loss: 0.0785 - val_mse: 0.0785\n",
      "Epoch 102/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0904 - mse: 0.0904 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 103/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 104/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.0810 - val_mse: 0.0810\n",
      "Epoch 105/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1071 - mse: 0.1071 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 106/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 107/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 108/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1027 - mse: 0.1027 - val_loss: 0.0819 - val_mse: 0.0819\n",
      "Epoch 109/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 110/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 111/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 112/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 113/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0904 - mse: 0.0904 - val_loss: 0.0795 - val_mse: 0.0795\n",
      "Epoch 114/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 115/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 116/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 117/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1096 - mse: 0.1096 - val_loss: 0.0803 - val_mse: 0.0803\n",
      "Epoch 118/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.0817 - val_mse: 0.0817\n",
      "Epoch 119/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0925 - mse: 0.0925 - val_loss: 0.0834 - val_mse: 0.0834\n",
      "Epoch 120/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 0.0816 - val_mse: 0.0816\n",
      "Epoch 121/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1002 - mse: 0.1002 - val_loss: 0.0795 - val_mse: 0.0795\n",
      "Starting iteration... 4\n",
      "[ 1.2708477  1.5817682 -0.6019796  0.4476776  0.7624573]\n",
      "Epoch 1/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0950 - mse: 0.0950 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 2/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 0.0889 - val_mse: 0.0889\n",
      "Epoch 3/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0783 - mse: 0.0783 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 4/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 5/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0902 - mse: 0.0902 - val_loss: 0.0840 - val_mse: 0.0840\n",
      "Epoch 6/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 7/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0981 - mse: 0.0981 - val_loss: 0.0882 - val_mse: 0.0882\n",
      "Epoch 8/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0936 - mse: 0.0936 - val_loss: 0.0868 - val_mse: 0.0868\n",
      "Epoch 9/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 0.0887 - val_mse: 0.0887\n",
      "Epoch 10/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0978 - mse: 0.0978 - val_loss: 0.0906 - val_mse: 0.0906\n",
      "Epoch 11/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1008 - mse: 0.1008 - val_loss: 0.0839 - val_mse: 0.0839\n",
      "Epoch 12/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1046 - mse: 0.1046 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 13/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1049 - mse: 0.1049 - val_loss: 0.0830 - val_mse: 0.0830\n",
      "Epoch 14/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 0.0889 - val_mse: 0.0889\n",
      "Epoch 15/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 16/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0804 - mse: 0.0804 - val_loss: 0.0797 - val_mse: 0.0797\n",
      "Epoch 17/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 18/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0989 - mse: 0.0989 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 19/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0934 - mse: 0.0934 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 20/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0912 - mse: 0.0912 - val_loss: 0.0816 - val_mse: 0.0816\n",
      "Epoch 21/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1038 - mse: 0.1038 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 22/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0879 - mse: 0.0879 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 23/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 24/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 0.0804 - val_mse: 0.0804\n",
      "Epoch 25/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 26/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1058 - mse: 0.1058 - val_loss: 0.0857 - val_mse: 0.0857\n",
      "Epoch 27/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1128 - mse: 0.1128 - val_loss: 0.0809 - val_mse: 0.0809\n",
      "Epoch 28/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 29/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0830 - mse: 0.0830 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 30/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1033 - mse: 0.1033 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 31/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0842 - val_mse: 0.0842\n",
      "Epoch 32/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.0809 - val_mse: 0.0809\n",
      "Epoch 33/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1059 - mse: 0.1059 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 34/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0863 - mse: 0.0863 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 35/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 0.0807 - val_mse: 0.0807\n",
      "Epoch 36/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0842 - val_mse: 0.0842\n",
      "Epoch 37/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1009 - mse: 0.1009 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 38/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 0.0830 - val_mse: 0.0830\n",
      "Epoch 39/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1054 - mse: 0.1054 - val_loss: 0.0825 - val_mse: 0.0825\n",
      "Epoch 40/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 0.0807 - val_mse: 0.0807\n",
      "Epoch 41/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 42/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 43/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1046 - mse: 0.1046 - val_loss: 0.0847 - val_mse: 0.0847\n",
      "Epoch 44/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.0849 - val_mse: 0.0849\n",
      "Epoch 45/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 46/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1070 - mse: 0.1070 - val_loss: 0.0839 - val_mse: 0.0839\n",
      "Epoch 47/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0943 - mse: 0.0943 - val_loss: 0.0854 - val_mse: 0.0854\n",
      "Epoch 48/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 49/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1017 - mse: 0.1017 - val_loss: 0.0811 - val_mse: 0.0811\n",
      "Epoch 50/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 51/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0782 - mse: 0.0782 - val_loss: 0.0804 - val_mse: 0.0804\n",
      "Epoch 52/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.0840 - val_mse: 0.0840\n",
      "Epoch 53/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.0861 - val_mse: 0.0861\n",
      "Epoch 54/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0946 - mse: 0.0946 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 55/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 0.0834 - val_mse: 0.0834\n",
      "Epoch 56/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 0.0841 - val_mse: 0.0841\n",
      "Epoch 57/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1070 - mse: 0.1070 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 58/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0793 - val_mse: 0.0793\n",
      "Epoch 59/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0943 - mse: 0.0943 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 60/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1051 - mse: 0.1051 - val_loss: 0.0845 - val_mse: 0.0845\n",
      "Epoch 61/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1029 - mse: 0.1029 - val_loss: 0.0810 - val_mse: 0.0810\n",
      "Epoch 62/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0972 - mse: 0.0972 - val_loss: 0.0847 - val_mse: 0.0847\n",
      "Epoch 63/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 64/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1006 - mse: 0.1006 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 65/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 66/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1008 - mse: 0.1008 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 67/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 68/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 0.0860 - val_mse: 0.0860\n",
      "Epoch 69/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0855 - mse: 0.0855 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 70/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0912 - mse: 0.0912 - val_loss: 0.0803 - val_mse: 0.0803\n",
      "Epoch 71/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0976 - mse: 0.0976 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 72/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 73/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0921 - mse: 0.0921 - val_loss: 0.0867 - val_mse: 0.0867\n",
      "Epoch 74/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 0.0810 - val_mse: 0.0810\n",
      "Epoch 75/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 76/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1006 - mse: 0.1006 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 77/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 78/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 79/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0866 - mse: 0.0866 - val_loss: 0.0867 - val_mse: 0.0867\n",
      "Epoch 80/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0990 - mse: 0.0990 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 81/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 0.0811 - val_mse: 0.0811\n",
      "Epoch 82/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0965 - mse: 0.0965 - val_loss: 0.0853 - val_mse: 0.0853\n",
      "Epoch 83/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 84/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 85/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 86/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 0.0772 - val_mse: 0.0772\n",
      "Epoch 87/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 88/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0978 - mse: 0.0978 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 89/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1070 - mse: 0.1070 - val_loss: 0.0882 - val_mse: 0.0882\n",
      "Epoch 90/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0959 - mse: 0.0959 - val_loss: 0.0819 - val_mse: 0.0819\n",
      "Epoch 91/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0845 - mse: 0.0845 - val_loss: 0.0863 - val_mse: 0.0863\n",
      "Epoch 92/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0977 - mse: 0.0977 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 93/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0899 - val_mse: 0.0899\n",
      "Epoch 94/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 0.0834 - val_mse: 0.0834\n",
      "Epoch 95/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 96/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1013 - mse: 0.1013 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 97/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 0.0807 - val_mse: 0.0807\n",
      "Epoch 98/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0842 - mse: 0.0842 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 99/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 100/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0987 - mse: 0.0987 - val_loss: 0.0836 - val_mse: 0.0836\n",
      "Epoch 101/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0893 - mse: 0.0893 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 102/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0895 - mse: 0.0895 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 103/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0825 - val_mse: 0.0825\n",
      "Epoch 104/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 0.0811 - val_mse: 0.0811\n",
      "Epoch 105/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0783 - mse: 0.0783 - val_loss: 0.0859 - val_mse: 0.0859\n",
      "Epoch 106/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 0.0833 - val_mse: 0.0833\n",
      "Epoch 107/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 108/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 109/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 110/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 111/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1059 - mse: 0.1059 - val_loss: 0.0837 - val_mse: 0.0837\n",
      "Epoch 112/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0966 - mse: 0.0966 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 113/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0925 - mse: 0.0925 - val_loss: 0.0809 - val_mse: 0.0809\n",
      "Epoch 114/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 115/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0933 - mse: 0.0933 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "Epoch 116/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 0.0809 - val_mse: 0.0809\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0976 - mse: 0.0976 - val_loss: 0.0831 - val_mse: 0.0831\n",
      "Starting iteration... 5\n",
      "[ 1.3588747   1.6016678  -0.64522886  0.38008675  0.7066322 ]\n",
      "Epoch 1/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0885 - mse: 0.0885 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 2/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0957 - mse: 0.0957 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 3/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.0795 - val_mse: 0.0795\n",
      "Epoch 4/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 0.0807 - val_mse: 0.0807\n",
      "Epoch 5/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0881 - mse: 0.0881 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 6/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0840 - mse: 0.0840 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 7/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.0772 - val_mse: 0.0772\n",
      "Epoch 8/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0997 - mse: 0.0997 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 9/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0891 - mse: 0.0891 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 10/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "Epoch 11/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1009 - mse: 0.1009 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 12/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.0781 - val_mse: 0.0781\n",
      "Epoch 13/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0791 - mse: 0.0791 - val_loss: 0.0796 - val_mse: 0.0796\n",
      "Epoch 14/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0963 - mse: 0.0963 - val_loss: 0.0834 - val_mse: 0.0834\n",
      "Epoch 15/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 0.0833 - val_mse: 0.0833\n",
      "Epoch 16/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0880 - val_mse: 0.0880\n",
      "Epoch 17/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1000 - mse: 0.1000 - val_loss: 0.0785 - val_mse: 0.0785\n",
      "Epoch 18/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.0887 - val_mse: 0.0887\n",
      "Epoch 19/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0911 - mse: 0.0911 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 20/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0887 - mse: 0.0887 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 21/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.0830 - val_mse: 0.0830\n",
      "Epoch 22/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 23/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 0.0797 - val_mse: 0.0797\n",
      "Epoch 24/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 25/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0865 - mse: 0.0865 - val_loss: 0.0797 - val_mse: 0.0797\n",
      "Epoch 26/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1054 - mse: 0.1054 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 27/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 28/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0795 - val_mse: 0.0795\n",
      "Epoch 29/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 0.0743 - val_mse: 0.0743\n",
      "Epoch 30/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1075 - mse: 0.1075 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 31/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0779 - mse: 0.0779 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 32/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0988 - mse: 0.0988 - val_loss: 0.0778 - val_mse: 0.0778\n",
      "Epoch 33/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 34/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 35/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1063 - mse: 0.1063 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Epoch 36/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 0.0843 - val_mse: 0.0843\n",
      "Epoch 37/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1012 - mse: 0.1012 - val_loss: 0.0761 - val_mse: 0.0761\n",
      "Epoch 38/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0847 - mse: 0.0847 - val_loss: 0.0727 - val_mse: 0.0727\n",
      "Epoch 39/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 40/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 0.0809 - val_mse: 0.0809\n",
      "Epoch 41/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0904 - val_mse: 0.0904\n",
      "Epoch 42/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0877 - val_mse: 0.0877\n",
      "Epoch 43/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.0844 - val_mse: 0.0844\n",
      "Epoch 44/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0779 - mse: 0.0779 - val_loss: 0.0809 - val_mse: 0.0809\n",
      "Epoch 45/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0888 - mse: 0.0888 - val_loss: 0.0856 - val_mse: 0.0856\n",
      "Epoch 46/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0799 - mse: 0.0799 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 47/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 48/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 49/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1000 - mse: 0.1000 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 50/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 51/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 52/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0987 - mse: 0.0987 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 53/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 0.0795 - val_mse: 0.0795\n",
      "Epoch 54/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 0.0789 - val_mse: 0.0789\n",
      "Epoch 55/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0868 - val_mse: 0.0868\n",
      "Epoch 56/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0817 - mse: 0.0817 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 57/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 0.0766 - val_mse: 0.0766\n",
      "Epoch 58/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0987 - mse: 0.0987 - val_loss: 0.0780 - val_mse: 0.0780\n",
      "Epoch 59/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 0.0797 - val_mse: 0.0797\n",
      "Epoch 60/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0830 - val_mse: 0.0830\n",
      "Epoch 61/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1061 - mse: 0.1061 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 62/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0814 - val_mse: 0.0814\n",
      "Epoch 63/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 0.0819 - val_mse: 0.0819\n",
      "Epoch 64/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0825 - val_mse: 0.0825\n",
      "Epoch 65/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0866 - mse: 0.0866 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 66/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1020 - mse: 0.1020 - val_loss: 0.0868 - val_mse: 0.0868\n",
      "Epoch 67/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0943 - mse: 0.0943 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 68/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1016 - mse: 0.1016 - val_loss: 0.0785 - val_mse: 0.0785\n",
      "Epoch 69/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 70/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0849 - mse: 0.0849 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 71/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 72/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 73/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0829 - mse: 0.0829 - val_loss: 0.0816 - val_mse: 0.0816\n",
      "Epoch 74/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 75/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0868 - mse: 0.0868 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 76/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 77/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0751 - mse: 0.0751 - val_loss: 0.0747 - val_mse: 0.0747\n",
      "Epoch 78/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 79/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 0.0803 - val_mse: 0.0803\n",
      "Epoch 80/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0738 - mse: 0.0738 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 81/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0993 - mse: 0.0993 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 82/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 83/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 84/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0858 - mse: 0.0858 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 85/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 0.0872 - val_mse: 0.0872\n",
      "Epoch 86/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0817 - mse: 0.0817 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 87/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0852 - mse: 0.0852 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 88/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0949 - mse: 0.0949 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Starting iteration... 6\n",
      "[ 1.3571041   1.4363977  -0.66802335  0.48429328  0.79577774]\n",
      "Epoch 1/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 2/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0863 - mse: 0.0863 - val_loss: 0.0785 - val_mse: 0.0785\n",
      "Epoch 3/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 4/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1002 - mse: 0.1002 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "Epoch 5/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0778 - mse: 0.0778 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 6/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0781 - val_mse: 0.0781\n",
      "Epoch 7/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 8/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 9/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0789 - mse: 0.0789 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 10/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0977 - mse: 0.0977 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 11/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0866 - mse: 0.0866 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 12/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0831 - mse: 0.0831 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 13/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 0.0840 - val_mse: 0.0840\n",
      "Epoch 14/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0775 - mse: 0.0775 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 15/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 16/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Epoch 17/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0927 - mse: 0.0927 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Epoch 18/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0846 - mse: 0.0846 - val_loss: 0.0836 - val_mse: 0.0836\n",
      "Epoch 19/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Epoch 20/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0820 - mse: 0.0820 - val_loss: 0.0908 - val_mse: 0.0908\n",
      "Epoch 21/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0857 - mse: 0.0857 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 22/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 0.0800 - val_mse: 0.0800\n",
      "Epoch 23/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 24/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0943 - mse: 0.0943 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 25/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0811 - val_mse: 0.0811\n",
      "Epoch 26/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 27/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0750 - val_mse: 0.0750\n",
      "Epoch 28/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0999 - mse: 0.0999 - val_loss: 0.0860 - val_mse: 0.0860\n",
      "Epoch 29/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 30/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0901 - mse: 0.0901 - val_loss: 0.0789 - val_mse: 0.0789\n",
      "Epoch 31/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 33/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0790 - mse: 0.0790 - val_loss: 0.0807 - val_mse: 0.0807\n",
      "Epoch 34/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0793 - mse: 0.0793 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 35/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0801 - mse: 0.0801 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 36/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0954 - mse: 0.0954 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 37/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1052 - mse: 0.1052 - val_loss: 0.0791 - val_mse: 0.0791\n",
      "Epoch 38/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0769 - mse: 0.0769 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 39/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0865 - mse: 0.0865 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 40/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0772 - mse: 0.0772 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 41/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0783 - mse: 0.0783 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 42/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0902 - mse: 0.0902 - val_loss: 0.0816 - val_mse: 0.0816\n",
      "Epoch 43/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0746 - mse: 0.0746 - val_loss: 0.0741 - val_mse: 0.0741\n",
      "Epoch 44/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 45/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 46/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 47/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 48/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 0.0814 - val_mse: 0.0814\n",
      "Epoch 49/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0898 - mse: 0.0898 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 50/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0754 - mse: 0.0754 - val_loss: 0.0809 - val_mse: 0.0809\n",
      "Epoch 51/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0785 - mse: 0.0785 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 52/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0838 - val_mse: 0.0838\n",
      "Epoch 53/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 54/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0743 - mse: 0.0743 - val_loss: 0.0861 - val_mse: 0.0861\n",
      "Epoch 55/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 56/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 57/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0841 - mse: 0.0841 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Starting iteration... 7\n",
      "[ 1.3247465   1.5654297  -0.70037276  0.455486    0.78181815]\n",
      "Epoch 1/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 2/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0884 - mse: 0.0884 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 3/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0761 - mse: 0.0761 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 4/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 5/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 6/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0847 - mse: 0.0847 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 7/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0769 - mse: 0.0769 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 8/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0840 - mse: 0.0840 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 9/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0884 - mse: 0.0884 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 10/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0913 - mse: 0.0913 - val_loss: 0.0812 - val_mse: 0.0812\n",
      "Epoch 11/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0835 - mse: 0.0835 - val_loss: 0.0819 - val_mse: 0.0819\n",
      "Epoch 12/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0843 - val_mse: 0.0843\n",
      "Epoch 13/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 0.0825 - val_mse: 0.0825\n",
      "Epoch 14/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0795 - mse: 0.0795 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 15/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 16/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0801 - mse: 0.0801 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 17/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 18/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0796 - mse: 0.0796 - val_loss: 0.0780 - val_mse: 0.0780\n",
      "Epoch 19/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 20/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 21/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 22/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0888 - mse: 0.0888 - val_loss: 0.0780 - val_mse: 0.0780\n",
      "Epoch 23/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1008 - mse: 0.1008 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 24/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 25/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 26/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0954 - mse: 0.0954 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 27/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0948 - mse: 0.0948 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 28/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 29/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0852 - mse: 0.0852 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 30/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 31/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0817 - val_mse: 0.0817\n",
      "Epoch 32/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0782 - mse: 0.0782 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 33/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0754 - mse: 0.0754 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 34/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0836 - val_mse: 0.0836\n",
      "Epoch 35/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0799 - mse: 0.0799 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 36/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0840 - mse: 0.0840 - val_loss: 0.0857 - val_mse: 0.0857\n",
      "Epoch 37/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 38/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0959 - mse: 0.0959 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 39/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0958 - mse: 0.0958 - val_loss: 0.0817 - val_mse: 0.0817\n",
      "Epoch 40/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 41/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0822 - mse: 0.0822 - val_loss: 0.0812 - val_mse: 0.0812\n",
      "Epoch 42/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0841 - mse: 0.0841 - val_loss: 0.0861 - val_mse: 0.0861\n",
      "Epoch 43/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.0873 - val_mse: 0.0873\n",
      "Epoch 44/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0939 - mse: 0.0939 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 45/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 46/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0880 - mse: 0.0880 - val_loss: 0.0848 - val_mse: 0.0848\n",
      "Epoch 47/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1013 - mse: 0.1013 - val_loss: 0.0885 - val_mse: 0.0885\n",
      "Epoch 48/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.0870 - val_mse: 0.0870\n",
      "Epoch 49/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.0847 - val_mse: 0.0847\n",
      "Epoch 50/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 51/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1010 - mse: 0.1010 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 52/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0808 - mse: 0.0808 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 53/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0815 - mse: 0.0815 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 54/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0778 - mse: 0.0778 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 55/1000\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.0888 - mse: 0.0888 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 56/1000\n",
      " 25/175 [===>..........................] - ETA: 0s - loss: 0.1074 - mse: 0.1074"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-34e384478a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         params_df,z_final = simulate_mediation(df,mediator,output_df,\n\u001b[1;32m     19\u001b[0m                                       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                       True,n,runs,num_iters)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mparams_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'simulation-2-image-size-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-part-5.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3b80e93c8543>\u001b[0m in \u001b[0;36msimulate_mediation\u001b[0;34m(df, M, params_df, model, algo, num_subs, batch_size, epochs, tune, n, n_runs, iterations)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     history = model.fit(M,d,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=[es],\n\u001b[0;32m--> 114\u001b[0;31m                                       shuffle=True,validation_split = 0.3)\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     history = model.fit(M,d,batch_size=batch_size,epochs=epochs,verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/deep_structure/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "for n in new_shape:\n",
    "    start = 0\n",
    "    output_df = create_empty_df(num_runs,num_iters)\n",
    "    for runs in range(start,num_runs):\n",
    "        K.clear_session()\n",
    "        print(\"Running simulation for image shape %s starting with %s runs\"%(n,runs+1))\n",
    "    # simulate the dataset\n",
    "        df,mediator,z = auxiliaryfunctions.simulate_dataset(num_subs,resize= True,\n",
    "                                          new_shape=n,algo=algo,visualize=False,alpha=0.2)\n",
    "        # create a model \n",
    "        if algo == 'svr':\n",
    "            model = auxiliaryfunctions.create_svr_model(mediator,df.m)\n",
    "        elif algo== 'shallow':\n",
    "            input_shape = (new_shape[0],new_shape[1]*4,1)\n",
    "            model = auxiliaryfunctions.create_shallow_model2D(input_shape=input_shape)\n",
    "        else:\n",
    "            input_shape = (new_shape[0],new_shape[1]*4,1)\n",
    "            model = auxiliaryfunctions.create_deep_model2D(input_shape=input_shape)\n",
    "\n",
    "        params_df,z_final = simulate_mediation(df,mediator,output_df,\n",
    "                                      model,algo,n,batch_size,epochs,\n",
    "                                      True,n,runs,num_iters)\n",
    "        params_df.to_excel(os.path.join(result_path,'simulation-2-image-size-'+str(n[0])+'.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 32]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  6 18:35:25 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    46W / 300W |      0MiB / 16160MiB |      4%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    42W / 300W |  15653MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A      1652      C   ...deep_structure/bin/python    15651MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_structure] *",
   "language": "python",
   "name": "conda-env-deep_structure-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
